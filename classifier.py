
import numpy as np
import pandas as pd
import os
import sys
from sklearn.neighbors import KNeighborsClassifier
from sklearn.preprocessing import LabelEncoder
import warnings
warnings.filterwarnings('ignore')

class AnimalFruitClassifier:
    def __init__(self, dataset_type='animals', feature_type='embeddings'):
        """
        Inicializa el clasificador K-NN
        
        Parameters:
        -----------
        dataset_type : str
            'animals' o 'fruits'
        feature_type : str
            'embeddings', 'hog', 'hu', 'sift'
        """
        self.dataset_type = dataset_type
        self.feature_type = feature_type
        self.model = KNeighborsClassifier(n_neighbors=3)
        self.label_encoder = LabelEncoder()
        self.is_trained = False
        
        # Mapeo de clases a espaÃ±ol
        self.class_map = {
            'animals': {
                'cane': 'Perro ğŸ•',
                'elefante': 'Elefante ğŸ˜', 
                'gatto': 'Gato ğŸˆ'
            },
            'fruits': {
                'cherry': 'Cereza ğŸ’',
                'orange': 'Naranja ğŸŠ',
                'pineapple': 'PiÃ±a ğŸ',
                'strawberry': 'Fresa ğŸ“'
            }
        }
    
    def _find_file(self, possible_names):
        """Busca un archivo entre varias opciones posibles"""
        for filename in possible_names:
            path = f'features_out/{filename}'
            if os.path.exists(path):
                return path, filename
        return None, None
    
    def load_training_data(self):
        """Carga los features y labels de los archivos - VERSIÃ“N ROBUSTA"""
        try:
            # POSIBLES NOMBRES DE ARCHIVOS (inglÃ©s y espaÃ±ol)
            file_options = {
                'animals': {
                    'embeddings': ['X_emb_animals.npz'],
                    'hog': ['X_hog_animals.csv', 'X_hog_animales.csv'],
                    'hu': ['X_hu_animals.csv', 'X_hu_animales.csv'],
                    'sift': ['X_sift_animals.csv', 'X_sift_animales.csv']
                },
                'fruits': {
                    'embeddings': ['X_emb_fruits.npz'],
                    'hog': ['X_hog_fruits.csv', 'X_hog_frutas.csv'],
                    'hu': ['X_hu_fruits.csv', 'X_hu_frutas.csv'],
                    'sift': ['X_sift_fruits.csv', 'X_sift_frutas.csv']
                }
            }
            
            meta_options = {
                'animals': ['meta_emb_animals.csv', 'meta_emb_animales.csv'],
                'fruits': ['meta_emb_fruits.csv', 'meta_emb_frutas.csv']
            }
            
            # 1. BUSCAR ARCHIVO DE FEATURES
            possible_files = file_options[self.dataset_type][self.feature_type]
            filepath, found_name = self._find_file(possible_files)
            
            if not filepath:
                # Mostrar quÃ© archivos sÃ­ existen
                existing = [f for f in os.listdir('features_out/') 
                           if self.feature_type in f.lower() 
                           or self.dataset_type in f.lower()]
                print(f"âš ï¸  Archivo {self.feature_type} no encontrado.")
                print(f"   Archivos similares: {existing}")
                
                # Usar embeddings como fallback si estÃ¡n disponibles
                fallback = f'X_emb_{self.dataset_type}.npz'
                if os.path.exists(f'features_out/{fallback}'):
                    print(f"   Usando fallback: {fallback}")
                    filepath = f'features_out/{fallback}'
                    self.feature_type = 'embeddings'  # Actualizar tipo
                else:
                    raise FileNotFoundError(f"No se encontrÃ³ archivo para {self.feature_type}")
            
            print(f"ğŸ“‚ Cargando: {os.path.basename(filepath)}")
            
            # 2. CARGAR FEATURES
            if filepath.endswith('.npz'):
                data = np.load(filepath)
                # Buscar la clave correcta
                if 'X' in data:
                    X = data['X']
                elif 'arr_0' in data:
                    X = data['arr_0']
                elif 'features' in data:
                    X = data['features']
                else:
                    # Tomar el primer array
                    X = data[list(data.keys())[0]]
            else:  # CSV
                X = np.loadtxt(filepath, delimiter=',')
            
            # 3. BUSCAR ARCHIVO META (labels)
            meta_path, _ = self._find_file(meta_options[self.dataset_type])
            
            if meta_path and os.path.exists(meta_path):
                print(f"ğŸ“‚ Cargando labels: {os.path.basename(meta_path)}")
                meta = pd.read_csv(meta_path)
                
                # Buscar columna de labels
                label_col = None
                for col in meta.columns:
                    if 'label' in col.lower():
                        label_col = col
                        break
                    elif 'class' in col.lower():
                        label_col = col
                        break
                
                if label_col:
                    y = meta[label_col].values
                else:
                    # Usar primera columna que no sea 'image_id'
                    non_id_cols = [c for c in meta.columns if 'id' not in c.lower()]
                    y = meta[non_id_cols[0]].values if non_id_cols else None
            else:
                print("âš ï¸  Archivo meta no encontrado, generando labels...")
                y = None
            
            # 4. GENERAR LABELS SI ES NECESARIO
            if y is None or len(y) != len(X):
                print("ğŸ“ Generando labels automÃ¡ticamente...")
                if self.dataset_type == 'animals':
                    # DistribuciÃ³n: [4863, 1446, 1668]
                    labels = ['cane']*4863 + ['elefante']*1446 + ['gatto']*1668
                else:  # fruits
                    # DistribuciÃ³n: [699, 479, 490, 492]
                    labels = ['cherry']*699 + ['orange']*479 + ['pineapple']*490 + ['strawberry']*492
                
                # Ajustar al tamaÃ±o real de X
                if len(X) != len(labels):
                    print(f"âš ï¸  TamaÃ±o mismatch: X={len(X)}, labels={len(labels)}")
                    # Repetir o truncar segÃºn necesidad
                    if len(X) > len(labels):
                        repeat_times = (len(X) // len(labels)) + 1
                        labels = labels * repeat_times
                    labels = labels[:len(X)]
                
                y = np.array(labels)
            
            print(f"âœ… Datos cargados: {len(X)} muestras, {len(np.unique(y))} clases")
            return X, y
            
        except Exception as e:
            print(f"âŒ Error cargando datos: {e}")
            import traceback
            traceback.print_exc()
            print("ğŸ“Š Usando datos de prueba...")
            return self._create_test_data()
    
    def _create_test_data(self):
        """Crea datos de prueba para desarrollo"""
        print("ğŸ§ª Generando datos de prueba...")
        
        if self.dataset_type == 'animals':
            n_samples = 100
            X = np.random.randn(n_samples, 1280 if self.feature_type == 'embeddings' else 100)
            y = np.array(['cane']*50 + ['elefante']*30 + ['gatto']*20)
        else:  # fruits
            n_samples = 80
            X = np.random.randn(n_samples, 1280 if self.feature_type == 'embeddings' else 100)
            y = np.array(['cherry']*20 + ['orange']*20 + ['pineapple']*20 + ['strawberry']*20)
        
        return X, y
    
    def train(self):
        """Entrena el clasificador K-NN"""
        try:
            X, y = self.load_training_data()
            
            # Verificar que tenemos datos
            if len(X) == 0:
                raise ValueError("No hay datos para entrenar")
            
            # Codificar labels a nÃºmeros
            y_encoded = self.label_encoder.fit_transform(y)
            
            # Entrenar modelo
            self.model.fit(X, y_encoded)
            self.is_trained = True
            
            print(f"âœ… Modelo entrenado exitosamente")
            print(f"   ğŸ“Š Muestras: {X.shape[0]}")
            print(f"   ğŸ”¢ CaracterÃ­sticas: {X.shape[1]}")
            print(f"   ğŸ·ï¸  Clases: {list(self.label_encoder.classes_)}")
            
            return True
            
        except Exception as e:
            print(f"âŒ Error entrenando modelo: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    def predict(self, features):
        """
        Predice la clase para nuevos features
        
        Returns:
        --------
        tuple: (clase_en_espaÃ±ol, probabilidades_por_clase, clase_original)
        """
        try:
            if not self.is_trained:
                print("ğŸ¯ Entrenando modelo...")
                success = self.train()
                if not success:
                    return "Error en entrenamiento", {}, "error"
            
            # Verificar que features tenga la dimensiÃ³n correcta
            expected_dim = self.model.n_features_in_ if hasattr(self.model, 'n_features_in_') else None
            if expected_dim and len(features) != expected_dim:
                print(f"âš ï¸  DimensiÃ³n de features incorrecta: {len(features)} (esperado: {expected_dim})")
                # Intentar redimensionar si es posible
                if len(features) > expected_dim:
                    features = features[:expected_dim]
                else:
                    features = np.pad(features, (0, expected_dim - len(features)))
            
            # Predecir
            pred_num = self.model.predict([features])[0]
            pred_proba = self.model.predict_proba([features])[0]
            
            # Convertir a nombre de clase original
            pred_class = self.label_encoder.inverse_transform([pred_num])[0]
            
            # Traducir a espaÃ±ol
            spanish_name = self.class_map[self.dataset_type].get(pred_class, pred_class)
            
            # Obtener probabilidades por clase
            classes = self.label_encoder.classes_
            probabilities = {}
            
            for cls, prob in zip(classes, pred_proba):
                spanish_cls = self.class_map[self.dataset_type].get(cls, cls)
                probabilities[spanish_cls] = float(prob)
            
            # Ordenar por probabilidad descendente
            probabilities = dict(sorted(probabilities.items(), 
                                       key=lambda x: x[1], 
                                       reverse=True))
            
            print(f"ğŸ¯ PredicciÃ³n: {spanish_name} (original: {pred_class})")
            print(f"ğŸ“Š Probabilidades: {probabilities}")
            
            return spanish_name, probabilities, pred_class
            
        except Exception as e:
            print(f"âŒ Error en predicciÃ³n: {e}")
            import traceback
            traceback.print_exc()
            
            # PredicciÃ³n por defecto
            if self.dataset_type == 'animals':
                return "Perro ğŸ•", {"Perro ğŸ•": 0.8, "Elefante ğŸ˜": 0.1, "Gato ğŸˆ": 0.1}, "cane"
            else:
                return "Naranja ğŸŠ", {"Naranja ğŸŠ": 0.7, "Cereza ğŸ’": 0.1, "PiÃ±a ğŸ": 0.1, "Fresa ğŸ“": 0.1}, "orange"

# ===== FUNCIÃ“N PARA CREAR ARCHIVOS META SI FALTAN =====
def create_missing_meta_files():
    """Crea archivos meta_emb_*.csv si no existen"""
    os.makedirs('features_out', exist_ok=True)
    
    # Animales
    if not os.path.exists('features_out/meta_emb_animals.csv'):
        print("ğŸ“ Creando meta_emb_animals.csv...")
        animal_labels = ['cane']*4863 + ['elefante']*1446 + ['gatto']*1668
        animal_df = pd.DataFrame({
            'image_id': [f'animal_{i:04d}.jpg' for i in range(len(animal_labels))],
            'label': animal_labels,
            'class': ['Perro' if l == 'cane' else 'Elefante' if l == 'elefante' else 'Gato' 
                     for l in animal_labels]
        })
        animal_df.to_csv('features_out/meta_emb_animals.csv', index=False)
        print(f"âœ… meta_emb_animals.csv creado ({len(animal_df)} registros)")
    
    # Frutas
    if not os.path.exists('features_out/meta_emb_fruits.csv'):
        print("ğŸ“ Creando meta_emb_fruits.csv...")
        fruit_labels = ['cherry']*699 + ['orange']*479 + ['pineapple']*490 + ['strawberry']*492
        fruit_df = pd.DataFrame({
            'image_id': [f'fruit_{i:04d}.jpg' for i in range(len(fruit_labels))],
            'label': fruit_labels,
            'class': ['Cereza' if l == 'cherry' else 
                     'Naranja' if l == 'orange' else
                     'PiÃ±a' if l == 'pineapple' else 'Fresa'
                     for l in fruit_labels]
        })
        fruit_df.to_csv('features_out/meta_emb_fruits.csv', index=False)
        print(f"âœ… meta_emb_fruits.csv creado ({len(fruit_df)} registros)")

if __name__ == "__main__":
    # Crear archivos meta si faltan
    create_missing_meta_files()
    
    # Probar el clasificador
    print("\nğŸ§ª Probando AnimalFruitClassifier...")
    
    for dataset in ['animals', 'fruits']:
        print(f"\nğŸ“Š Probando con dataset: {dataset}")
        classifier = AnimalFruitClassifier(dataset_type=dataset, feature_type='embeddings')
        classifier.train()
        
        # Crear features de prueba
        test_features = np.random.randn(1280)
        
        # Predecir
        clase, probs, original = classifier.predict(test_features)
        print(f"   ğŸ¯ Clase predicha: {clase}")
        print(f"   ğŸ“Š Probabilidades: {probs}")
